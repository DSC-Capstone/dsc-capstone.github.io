<!DOCTYPE html><html lang="en-US"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=Edge"><link rel="shortcut icon" href="/favicon.ico" type="image/x-icon"><link rel="stylesheet" href="/assets/css/just-the-docs-default.css"> <script src="/assets/js/vendor/lunr.min.js"></script> <script src="/assets/js/just-the-docs.js"></script><meta name="viewport" content="width=device-width, initial-scale=1"><title>Lesson 2 – Project Organization | DSC 180AB</title><meta name="generator" content="Jekyll v3.9.2" /><meta property="og:title" content="Lesson 2 – Project Organization" /><meta name="author" content="Suraj Rampure" /><meta property="og:locale" content="en_US" /><meta name="description" content="DSC 180AB, Fall 2023 and Winter 2024 at UC San Diego" /><meta property="og:description" content="DSC 180AB, Fall 2023 and Winter 2024 at UC San Diego" /><link rel="canonical" href="http://localhost:4000/lessons/q1/02/" /><meta property="og:url" content="http://localhost:4000/lessons/q1/02/" /><meta property="og:site_name" content="DSC 180AB" /><meta property="og:type" content="website" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Lesson 2 – Project Organization" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"WebPage","author":{"@type":"Person","name":"Suraj Rampure"},"description":"DSC 180AB, Fall 2023 and Winter 2024 at UC San Diego","headline":"Lesson 2 – Project Organization","url":"http://localhost:4000/lessons/q1/02/"}</script><body> <a class="skip-to-main" href="#main-content">Skip to main content</a> <svg xmlns="http://www.w3.org/2000/svg" style="display: none;"> <symbol id="svg-link" viewBox="0 0 24 24"><title>Link</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path> </svg> </symbol> <symbol id="svg-search" viewBox="0 0 24 24"><title>Search</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search"> <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line> </svg> </symbol> <symbol id="svg-menu" viewBox="0 0 24 24"><title>Menu</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"><line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line> </svg> </symbol> <symbol id="svg-arrow-right" viewBox="0 0 24 24"><title>Expand</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right"><polyline points="9 18 15 12 9 6"></polyline> </svg> </symbol> <symbol id="svg-doc" viewBox="0 0 24 24"><title>Document</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file"><path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline> </svg> </symbol> <symbol id="svg-external-link" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-external-link"><title id="svg-external-link-title">(external link)</title><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path><polyline points="15 3 21 3 21 9"></polyline><line x1="10" y1="14" x2="21" y2="3"></line> </symbol> </svg><div class="side-bar"><div class="site-header"> <a href="/" class="site-title lh-tight"> DSC 180AB </a> <a href="#" id="menu-button" class="site-button"> <svg viewBox="0 0 24 24" class="icon"><use xlink:href="#svg-menu"></use></svg> </a></div><nav aria-label="Main" id="site-nav" class="site-nav"><ul class="nav-list"><li class="nav-list-item"><a href="/" class="nav-list-link">🏡 Home</a><li class="nav-list-item"><a href="/syllabus/" class="nav-list-link">📓 Syllabus</a><li class="nav-list-item"><a href="/office-hours/" class="nav-list-link">📆 Office Hours</a><li class="nav-list-item"><a href="/staff/" class="nav-list-link">🙋 Staff</a><li class="nav-list-item"><a href="/mentors/" class="nav-list-link">👨‍🏫 Mentor Guide</a><li class="nav-list-item"><a href="/archive/" class="nav-list-link">💾 Archive</a></ul></nav><footer class="site-footer"> This site uses <a href="https://github.com/just-the-docs/just-the-docs">Just the Docs</a>, a documentation theme for Jekyll.</footer></div><div class="main" id="top"><div id="main-header" class="main-header"><div class="search"><div class="search-input-wrap"> <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search DSC 180AB" aria-label="Search DSC 180AB" autocomplete="off"> <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label></div><div id="search-results" class="search-results"></div></div><nav aria-label="Auxiliary" class="aux-nav"><ul class="aux-nav-list"><li class="aux-nav-list-item"> <a href="https://www.gradescope.com/courses/637426" class="site-button" > Gradescope </a><li class="aux-nav-list-item"> <a href="https://edstem.org/us/courses/48541/discussion/" class="site-button" > Ed </a><li class="aux-nav-list-item"> <a href="https://dsc-capstone.github.io/enrollment" class="site-button" > List of Domains </a><li class="aux-nav-list-item"> <a href="https://dsc-capstone.github.io/2022-23" class="site-button" > 2022-23 Showcase </a></ul></nav></div><div id="main-content-wrap" class="main-content-wrap"><div id="main-content" class="main-content" role="main"> <script type="text/javascript" async="" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"> </script><h1 class="no_toc" id="lesson-2--project-organization"> <a href="#lesson-2--project-organization" class="anchor-heading" aria-labelledby="lesson-2--project-organization"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Lesson 2 – Project Organization</h1><p>All lectures will be delivered as readings that you complete on your own time. Post questions with the lesson <a href="https://edstem.org/us/courses/28947/discussion/1876813">here</a>.</p><p>Make sure to read this article before moving on to <a href="../../../assignments/methodology/q1/02">Methodology Assignment 2</a>.</p><p><strong>Note:</strong> Take a look at the new <a href="../../../resources">Resources</a> tab of the course website.</p><hr /><h2 class="no_toc text-delta" id="table-of-contents"> <a href="#table-of-contents" class="anchor-heading" aria-labelledby="table-of-contents"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Table of contents</h2><ol id="markdown-toc"><li><a href="#goals-of-data-science-software-development" id="markdown-toc-goals-of-data-science-software-development">Goals of Data Science Software Development</a><ol><li><a href="#overview" id="markdown-toc-overview">Overview</a><li><a href="#managing-project-components" id="markdown-toc-managing-project-components">Managing Project Components</a></ol><li><a href="#the-anatomy-of-a-data-science-project" id="markdown-toc-the-anatomy-of-a-data-science-project">The Anatomy of a Data Science Project</a><ol><li><a href="#domain-research" id="markdown-toc-domain-research">Domain Research</a><li><a href="#question--hypothesis" id="markdown-toc-question--hypothesis">Question / Hypothesis</a><li><a href="#data-etl-extract-transform-load" id="markdown-toc-data-etl-extract-transform-load">Data ETL (extract, transform, load)</a><li><a href="#model-building" id="markdown-toc-model-building">Model Building</a><li><a href="#continued-prediction" id="markdown-toc-continued-prediction">Continued Prediction</a><li><a href="#conclusions-and-reports" id="markdown-toc-conclusions-and-reports">Conclusions and Reports</a><li><a href="#summary" id="markdown-toc-summary">Summary</a><li><a href="#caveat-methods-focused-projects" id="markdown-toc-caveat-methods-focused-projects">Caveat: Methods-Focused Projects</a></ol><li><a href="#an-initial-template-for-data-science-projects" id="markdown-toc-an-initial-template-for-data-science-projects">An Initial Template for Data Science Projects</a><ol><li><a href="#configuration-vs-code" id="markdown-toc-configuration-vs-code">Configuration vs. Code</a><li><a href="#a-simple-template" id="markdown-toc-a-simple-template">A Simple Template</a><li><a href="#a-simple-example" id="markdown-toc-a-simple-example">A Simple Example</a><ol><li><a href="#readmemd" id="markdown-toc-readmemd"><code class="language-plaintext highlighter-rouge">README.md</code></a><li><a href="#etlpy" id="markdown-toc-etlpy"><code class="language-plaintext highlighter-rouge">etl.py</code></a><li><a href="#data-paramsjson" id="markdown-toc-data-paramsjson"><code class="language-plaintext highlighter-rouge">data-params.json</code></a><li><a href="#runpy" id="markdown-toc-runpy"><code class="language-plaintext highlighter-rouge">run.py</code></a></ol></ol><li><a href="#a-final-template" id="markdown-toc-a-final-template">A Final Template</a><ol><li><a href="#overview-1" id="markdown-toc-overview-1">Overview</a><li><a href="#the-template" id="markdown-toc-the-template">The Template</a><ol><li><a href="#data" id="markdown-toc-data"><code class="language-plaintext highlighter-rouge">data</code></a><li><a href="#notebooks" id="markdown-toc-notebooks"><code class="language-plaintext highlighter-rouge">notebooks</code></a><li><a href="#requirementstxt" id="markdown-toc-requirementstxt"><code class="language-plaintext highlighter-rouge">requirements.txt</code></a></ol><li><a href="#examples" id="markdown-toc-examples">Examples</a></ol></ol><hr /><h2 id="goals-of-data-science-software-development"> <a href="#goals-of-data-science-software-development" class="anchor-heading" aria-labelledby="goals-of-data-science-software-development"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Goals of Data Science Software Development</h2><h3 id="overview"> <a href="#overview" class="anchor-heading" aria-labelledby="overview"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Overview</h3><p>At a high level, the <strong>data science lifecycle</strong> looks a lot like the scientific method you saw in elementary school.</p><center><img src="assets/scientific-method.png" width="30%" /></center><p>While you may begin with a single question, after performing exploratory data analysis and building a model to answer your question, you will likely refine your original question or come up with more questions to investigate. As a result, the code that you write needs to be written so that it can support iteratively changing questions and analyses. Specifically, the code for a data science project needs to be:</p><ol><li>Flexibly written, to adapt to changing questions.<li>Clearly documented, so that is clear – both to you and others using your code – what each piece does.<li>Reproducible, meaning that others should be able to run it themselves.</ol><p>In theory, that sounds pretty straightforward. However, as you saw in DSC 80, the real data science lifecycle is anything but.</p><p><a name="DSLC"></a></p><center><img src="assets/DSLC.png" width="40%" /></center><p>This makes it even more crucial that you follow the three principles outlined above. If you’re not careful, it’s easy to fall in the trap of writing poorly organized code with many hard-coded pieces. This results in:</p><ul><li>Being able to execute fewer iterations of your project, and as a result, making slower progress on your project.<li>Being unsure of <em>what</em> your code is even doing, increasing the likelihood of making mistakes while iterating and making it unclear what your conclusions even are.<li>Making it less likely that others will be able to use and replicate the results of your project, resulting in your project fading into obscurity.</ul><p>The purpose of this lesson is to show you how to adhere to the three principles mentioned above, as <strong>this will increase your chances of successfully executing your project</strong>. The contents of this lesson will be relevant for the remainder of the capstone sequence; you will find yourself coming back to it often in the future.</p><h3 id="managing-project-components"> <a href="#managing-project-components" class="anchor-heading" aria-labelledby="managing-project-components"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Managing Project Components</h3><p>There are a plethora of tools used in industry for managing data science projects, far too many for us to make a dent in them in this course. Instead, we will expose you to a few popular tools that help solve core issues that will be relevant even decades in the future, once the current slate of tools is replaced.</p><center> <img src="assets/all-tools.png" width="60%" /><br /> <i>A small sample of tools that exist for managing data science projects.</i> </center><p>These core issues revolve around the fact that your project will be made up of several components. For instance, you may have separate components for ingesting and cleaning raw data, creating visualizations, and training models. Issues you need to be aware of are:</p><ul><li><strong>Communication</strong>: How do these components all communicate with one another? In other words, what are the inputs and outputs of each component? It’s important to be clear about what these are up front, to avoid confusion later on.<li><strong>Isolation</strong>: Your code should be written in a way such that each component is as isolated as possible. This way, when you want to make changes to one component – say, loading in another column at the very start of your pipeline – you don’t have to make changes to all of your other components. This may happen if you have aspects of your modeling pipeline, like feature names, hard-coded throughout several different files. (It would suck to have to buy a new dashboard for your car every time you get a flat tire – the same principle applies here.)<li><strong>Parallelization and Scale</strong>: It should be clear <em>when</em> each part of your project needs to be run, and whether different parts can be run in parallel. Similarly, it should be clear which components of your project will need to scale as the project grows in scope – for instance, if you collect 10x more data, at what stages will you need more compute resources?</ul><p>One way we will address all of these issues is through the use of <strong>configuration files</strong>, in which you can specify and track hypotheses and desired outputs. As such, when new questions arise, you won’t have to re-write your code; instead, you’ll just run it with different configurations.</p><hr /><h2 id="the-anatomy-of-a-data-science-project"> <a href="#the-anatomy-of-a-data-science-project" class="anchor-heading" aria-labelledby="the-anatomy-of-a-data-science-project"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> The Anatomy of a Data Science Project</h2><p>Let’s look at how each component of the <a href="#DSLC">data science lifecycle</a> interacts with your code.</p><h3 id="domain-research"> <a href="#domain-research" class="anchor-heading" aria-labelledby="domain-research"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Domain Research</h3><p>The code you write throughout your project will strongly depend on your domain. For instance, suppose you’re working with driver data. In your data cleaning step, you may choose to keep only the drivers whose ages are at least 16, the legal driving age in California. This is a choice you had to make given your knowledge of your domain.</p><p>You’ll make several such design decisions while working on your project:</p><ul><li>You may clean your data in a specific way.<li>You may choose a particular column as a “target,” and a subset of the remaining columns for features.<li>You may build certain kinds of models over others.</ul><p>It’s important to document these choices and the context between them. This justification will appear in two places:</p><ul><li>In your final reports. For instance, in the EDA section of your report, you’d talk about what steps you took to clean your data and why they make sense.<li>In code comments, whenever relevant. Take the drivers’ age example, for instance. In the line where you keep only the drivers who are at least 16, you may add <code class="language-plaintext highlighter-rouge"># legal driving age</code>.</ul><h3 id="question--hypothesis"> <a href="#question--hypothesis" class="anchor-heading" aria-labelledby="question--hypothesis"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Question / Hypothesis</h3><p>You may start with an initial question to investigate, but as your project evolves, so will the questions you’re interested in. To prevent having to re-write your codebase each time you come up with a new question, you should think about how your questions will be similar to one another so that you can <strong>parameterize</strong> your code.</p><p>Here’s an example. Suppose you’re looking at traffic stops data, and you’re interested in whether “younger” people (&lt; 30 years old) are stopped at higher rates than “older” people (&gt;= 30 years old). Suppose you’re also interested in answering this question across multiple years – say, for each year from 2016 through 2022 – and across multiple counties in California. The most straightforward approach here is to create functions that take in <code class="language-plaintext highlighter-rouge">year</code> and <code class="language-plaintext highlighter-rouge">county</code> as input and return just the data needed to look at stop rates for that combination of <code class="language-plaintext highlighter-rouge">year</code> and <code class="language-plaintext highlighter-rouge">county</code>. Then, in a <strong>configuration</strong> file, you can store all years and counties that you’re interested in. Finally, you can call your data processing and hypothesis testing routines on all combinations of parameters in your configuration file. Note that in this approach, <em>each combination of parameters leads to a different question / hypothesis</em>.</p><p>One of the benefits of using configuration files, in addition to keeping your code robust and flexible, is that we can tell a server to run our pipeline for different combinations of parameters on different threads or machines, so that we can conduct our investigations in parallel. For instance, suppose there are 7 years (2016-2022, including both endpoints) and 3 counties (San Diego County, Orange County, and Los Angeles County) that we’re interested in investigating. There are \(7 \cdot 3 = 21\) combinations of year and county – wouldn’t it be great if we could run our code for all 21 combinations at the same time?</p><p>If some aspect of your question is never going to change, e.g. if you’re always only going to be looking at San Diego County, then it’s fine to hard-code that throughout your codebase. However, it’s generally a good idea to parameterize any aspects of your codebase that <em>could</em> change to keep it adaptable to new questions.</p><p>In this course, we will typically store our configuration files in the JSON format, though there are a variety of other possible formats (YAML is popular, as are INI and CFG). You’ll see example configuration files later on in the lesson.</p><h3 id="data-etl-extract-transform-load"> <a href="#data-etl-extract-transform-load" class="anchor-heading" aria-labelledby="data-etl-extract-transform-load"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Data ETL (extract, transform, load)</h3><p>As your project evolves, the data that you’re working with may also change. For instance, the source where you’re pulling traffic stops data from may update daily with the previous day’s stop data. You need to make sure that your modeling component doesn’t break just because we pulled in a new day’s worth of data, or because an additional column was added from the data source. Of course, your code doesn’t have to handle <em>all possible data sources</em>, but you should anticipate possible changes and prepare for them.</p><p>Here, configuration files will again be useful. For instance, you should explicitly mention which columns you want to use for transformations and model building, so that any new columns that are added in don’t impact your model.</p><p>You should also think about <em>how</em> you’re accessing your data – an API? scraping? found a CSV online? – and <em>where</em> you’re storing it. To prevent having to re-pull your data each time your cleaning and transformation logic changes, separate the code you use for data ingestion from the code you use for cleaning and transformation, and store intermediate “raw” data to disk that you can re-use whenever you update your cleaning logic.</p><h3 id="model-building"> <a href="#model-building" class="anchor-heading" aria-labelledby="model-building"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Model Building</h3><p>As you’ve seen in earlier courses, the model building process is not straightforward – you’ll repeatedly try different combinations models and parameters until you feel that your model has sufficient <em>generalizability</em> to unseen data. Continuing with the theme of parametrization, it’s a good idea to store all “potential” parameters in configuration files, so that models can be trained and evaulated on different combinations in parallel.</p><p>Furthermore, it’s encouraged to use frameworks that enable “pipelining”, like <code class="language-plaintext highlighter-rouge">sklearn</code>, which you were exposed to in <a href="https://dsc-courses.github.io/dsc80-2022-sp/resources/lectures/lec23/lec23.html">DSC 80</a>.</p><h3 id="continued-prediction"> <a href="#continued-prediction" class="anchor-heading" aria-labelledby="continued-prediction"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Continued Prediction</h3><p>Often times, your project lives on well after you’ve built your “final” model. Your model may be deployed into production to make “live” predictions – for instance, each time you request a ride in the Uber app, it predicts the highest price you’ll pay for a ride.</p><p>The <code class="language-plaintext highlighter-rouge">model.predict</code> method that you’d use to make predictions in <code class="language-plaintext highlighter-rouge">sklearn</code> may actually be called via HTTP requests on a site that uses a Java backend. Once this happens, you may want to keep track of how well your model is performing – are its outputs still reasonable? Is it easy to re-train it to reflect updated data?</p><p>The use of pre-trained models, particularly in the case of deep neural networks, is quite popular today. For instance, you can easily use <a href="https://openai.com/api/">OpenAI’s GPT-3</a> language model without having to train it yourself. You should strive to build a model that you can similarly share with others, in the form of a Python package or a Docker container. That way, others can easily use your model to make predictions without having to run your entire pipeline.</p><h3 id="conclusions-and-reports"> <a href="#conclusions-and-reports" class="anchor-heading" aria-labelledby="conclusions-and-reports"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Conclusions and Reports</h3><p>The final reports that you create will be written in some sort of markup language, like Markdown, and will explain your results and contain justification for all of the design decisions you made. Your reports will likely involve tables and visualizations that are derived from data. You should try to set up your report such that it automatically generates tables and visualizations using the other components of your project, so that if, say, your data is updated, you can update your report just by re-running your entire pipeline. This, of course, is not possible if your report includes screenshots from other parts of your project; instead, you’ll need to programmatically create, save, and load images.</p><h3 id="summary"> <a href="#summary" class="anchor-heading" aria-labelledby="summary"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Summary</h3><p>In short, your projects should be:</p><ul><li>Flexible for quick iterations, through configuration files.<li>Understandable through consumers of the output, through documentation and reports.<li>Usable for developers and researchers extending your work, through documentation and containerization.</ul><h3 id="caveat-methods-focused-projects"> <a href="#caveat-methods-focused-projects" class="anchor-heading" aria-labelledby="caveat-methods-focused-projects"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Caveat: Methods-Focused Projects</h3><p>You may wonder how much of this is applicable to you if your project doesn’t involve data analysis. Indeed, many domains are more methods-focused, where they spend time developing new techniques for collecting or modelling data rather than the entire lifecycle.</p><p>If this is the case, in addition to following general best practices for software development in your domain, <strong>you will still have a data analysis portion in your project</strong>, if only to demonstrate the usage and value of whatever it is you developed. You may have two repositories, one for the software package you develop and one for your “example” analysis (the former of which will be much larger).</p><hr /><h2 id="an-initial-template-for-data-science-projects"> <a href="#an-initial-template-for-data-science-projects" class="anchor-heading" aria-labelledby="an-initial-template-for-data-science-projects"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> An Initial Template for Data Science Projects</h2><p>Now that you understand how each step of the data science lifecycle plays a role in your project’s structure, let’s tangibly look at how you might structure your project.</p><h3 id="configuration-vs-code"> <a href="#configuration-vs-code" class="anchor-heading" aria-labelledby="configuration-vs-code"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Configuration vs. Code</h3><p>Up until now in this lesson, we’ve repeatedly emphasized the use of configuration files for storing parameters. However, it’s not immediately obvious what parts of your pipeline belong in <em>code</em> and what parts belong in <em>configuration files</em>.</p><p>Code that is used by other processes is called library code, or source code. Your source code may be run in notebooks that you use for EDA and for creating visualizations, and will certainly be run in your final <code class="language-plaintext highlighter-rouge">run.py</code> file that runs your entire pipeline. Source code will mostly be contained in <code class="language-plaintext highlighter-rouge">.py</code> files (or <code class="language-plaintext highlighter-rouge">.java</code> or <code class="language-plaintext highlighter-rouge">.cpp</code> files, for example). You are already used to using generic functions from libraries like <code class="language-plaintext highlighter-rouge">pandas</code> and <code class="language-plaintext highlighter-rouge">numpy</code>; the only difference here is that you are writing these functions yourself.</p><p>Configuration files, then, consist of parameters that your source code will use as inputs. For the most part, you will write configuration files in <code class="language-plaintext highlighter-rouge">.json</code>, but you <em>could</em> also store configurations as global variables at the top of your scripts.</p><p>Aim to generalize, but don’t overly generalize. It’s fine to start writing code with some inputs “hard-coded”, e.g. write filtering logic that creates a DataFrame of traffic stops in 2021 in Orange County, but at some point you should step back and generalize.</p><h3 id="a-simple-template"> <a href="#a-simple-template" class="anchor-heading" aria-labelledby="a-simple-template"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> A Simple Template</h3><p>Here’s a basic “template.”</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Project
├── code.py
├── config.json
└── script.py
</code></pre></div></div><p>Note that this example directory shows 3 files that are all in the same folder. Shortly, we will see more realistic example templates with multiple directories.</p><p>Specifically:</p><ul><li><code class="language-plaintext highlighter-rouge">code.py</code> contains library code – that is, functions designed to execute your project. These functions should be parameterized to accept various inputs.<li><code class="language-plaintext highlighter-rouge">config.json</code> contains parameters for the functions in <code class="language-plaintext highlighter-rouge">code.py</code>.<li><code class="language-plaintext highlighter-rouge">script.py</code> imports <code class="language-plaintext highlighter-rouge">code</code>, loads <code class="language-plaintext highlighter-rouge">config.json</code>, and calls functions from the <code class="language-plaintext highlighter-rouge">code</code> module. (Note that this could also be a notebook, <code class="language-plaintext highlighter-rouge">script.ipynb</code>.)</ul><p>For instance, <code class="language-plaintext highlighter-rouge">script.py</code> may contain:</p><div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">code</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'config.json'</span><span class="p">,</span> <span class="s">'r'</span><span class="p">)</span> <span class="k">as</span> <span class="n">fh</span><span class="p">:</span>
    <span class="n">params</span> <span class="o">=</span> <span class="n">json</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">fh</span><span class="p">)</span>

<span class="n">code</span><span class="p">.</span><span class="n">run_process</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">)</span>
</code></pre></div></div><p>We will use the process above <strong>repeatedly</strong>.</p><p>(Aside: The <code class="language-plaintext highlighter-rouge">**</code> operator above <em>unpacks</em> the entries of the <code class="language-plaintext highlighter-rouge">params</code> dictionary, so that they are all passed directly as inputs to <code class="language-plaintext highlighter-rouge">code.run_process</code>. As a crude example, if <code class="language-plaintext highlighter-rouge">f = lambda x, y: x + y</code>, then <code class="language-plaintext highlighter-rouge">f(**{'x': 2, 'y': 3})</code> evaluates to <code class="language-plaintext highlighter-rouge">5</code>. Read <a href="https://www.educative.io/answers/what-is-unpacking-keyword-arguments-with-dictionaries-in-python">here</a> for more.)</p><h3 id="a-simple-example"> <a href="#a-simple-example" class="anchor-heading" aria-labelledby="a-simple-example"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> A Simple Example</h3><p>Let’s see how we might tangibly use the example template from above. Suppose we have code that pulls data from an API, and that the data is updated daily. We want to re-run this code regularly to update our stored data.</p><center><img src="assets/ingestion.png" width="40%" /></center><p>Our project may be structured as follows:</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Project
├── README.md
├── data-params.json
├── etl.py
└── run.py
</code></pre></div></div><p>Let’s look at each piece in detail.</p><h4 id="readmemd"> <a href="#readmemd" class="anchor-heading" aria-labelledby="readmemd"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <code class="language-plaintext highlighter-rouge">README.md</code></h4><p>All repositories you create should have <code class="language-plaintext highlighter-rouge">README</code> files that describe what is located where and how to run your project.</p><h4 id="etlpy"> <a href="#etlpy" class="anchor-heading" aria-labelledby="etlpy"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <code class="language-plaintext highlighter-rouge">etl.py</code></h4><p><code class="language-plaintext highlighter-rouge">etl.py</code> contains our source code (i.e. it corresponds to <code class="language-plaintext highlighter-rouge">code.py</code> from the template). The functions written here are generic, and will be used throughout the rest of the project.</p><p>Note that <em>users</em> of the code in <code class="language-plaintext highlighter-rouge">etl.py</code> (e.g. other people running your project who will just run <code class="language-plaintext highlighter-rouge">python run.py</code>) should not need to know <em>how</em> the code in <code class="language-plaintext highlighter-rouge">etl.py</code> works in order to use it. You probably don’t know how <code class="language-plaintext highlighter-rouge">pd.pivot_table</code> works under the hood, but you still use it – the same idea applies here. However, developers who want to extend your project <em>will</em> have to understand how the code in <code class="language-plaintext highlighter-rouge">etl.py</code> works, and for that reason it still needs to be well-documented. Your library code will <em>not</em> know who is going to call it, and for what purpose – the calling is done in <code class="language-plaintext highlighter-rouge">run.py</code>, using the parameters in <code class="language-plaintext highlighter-rouge">data-params.json</code>.</p><p>Here’s an example of what <code class="language-plaintext highlighter-rouge">etl.py</code> might look like.</p><div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="s">'''
etl.py contains functions used to download DataFrames containing traffic stops data for different years and counties.
'''</span>

<span class="k">def</span> <span class="nf">get_year_and_county</span><span class="p">(</span><span class="n">year</span><span class="p">,</span> <span class="n">county</span><span class="p">):</span>
    <span class="s">'''
    Return a DataFrame of traffic stops data for a given
    year and county.
    '''</span>
    <span class="p">...</span>    
    <span class="k">return</span> <span class="p">...</span>

<span class="k">def</span> <span class="nf">get_data</span><span class="p">(</span><span class="n">years</span><span class="p">,</span> <span class="n">counties</span><span class="p">,</span> <span class="n">outpath</span><span class="p">):</span>
    <span class="s">'''
    Downloads DataFrames and saves them as CSVs at the specified output directory for the given years and counties.

    :param: years: a list of years to collect
    :param: teams: a list of counties to collect
    :param: outpath: the directory in which to save the data.
    '''</span>
    <span class="k">for</span> <span class="n">year</span> <span class="ow">in</span> <span class="n">years</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">county</span> <span class="ow">in</span> <span class="n">counties</span><span class="p">:</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">get_year_and_county</span><span class="p">(</span><span class="n">year</span><span class="p">,</span> <span class="n">county</span><span class="p">)</span>
            <span class="n">data</span><span class="p">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">outpath</span><span class="p">,</span> <span class="sa">f</span><span class="s">'</span><span class="si">{</span><span class="n">year</span><span class="si">}</span><span class="s">-</span><span class="si">{</span><span class="n">county</span><span class="si">}</span><span class="s">.csv'</span><span class="p">))</span>
    <span class="k">return</span>
</code></pre></div></div><p>Note that the functions above are well-documented. In a notebook, after running <code class="language-plaintext highlighter-rouge">import etl</code>, I could run <code class="language-plaintext highlighter-rouge">etl.get_data?</code> and see an explanation of <em>what</em> <code class="language-plaintext highlighter-rouge">get_data</code> does.</p><h4 id="data-paramsjson"> <a href="#data-paramsjson" class="anchor-heading" aria-labelledby="data-paramsjson"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <code class="language-plaintext highlighter-rouge">data-params.json</code></h4><p><a href="#question--hypothesis">Earlier</a>, we used the example of wanting to pull traffic stops data for every combination of year between 2016 and 2022 and county from San Diego County, Orange County, and Los Angeles County. To do so, we can call the <code class="language-plaintext highlighter-rouge">get_data</code> function in <code class="language-plaintext highlighter-rouge">etl.py</code> with appropriate <code class="language-plaintext highlighter-rouge">years</code> and <code class="language-plaintext highlighter-rouge">teams</code> lists. <code class="language-plaintext highlighter-rouge">data-params.json</code> is the right place to store those lists.</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{
    "years": [2016, 2017, 2018, 2019, 2020, 2021, 2022],
    "counties": ["San Diego County", "Orange County", "Los Angeles County"],
    "outpath": "data/raw"
}
</code></pre></div></div><p>Note that you don’t need to know how the code in either <code class="language-plaintext highlighter-rouge">etl.py</code> or <code class="language-plaintext highlighter-rouge">run.py</code> works to specify parameters. All you need to do to pull new data is update the lists here. Also note that you can create multiple configuration files to keep a “record” of different parameters you’ve tried.</p><h4 id="runpy"> <a href="#runpy" class="anchor-heading" aria-labelledby="runpy"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <code class="language-plaintext highlighter-rouge">run.py</code></h4><p>This script puts everything together. It will import the code in <code class="language-plaintext highlighter-rouge">etl</code> and run it on the parameters in <code class="language-plaintext highlighter-rouge">data-params.json</code>. Note that it also serves as an example of how to use the functions in <code class="language-plaintext highlighter-rouge">etl.py</code>, for those who may not be familiar with how they work.</p><p>There are other tools that exist for writing build scripts – for instance, you may have heard of Makefiles. However, we will stick with writing Python files, as they are sufficient for our purposes.</p><p>Here’s an example of what <code class="language-plaintext highlighter-rouge">run.py</code> might look like.</p><div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#!/usr/bin/env python
</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">json</span>

<span class="kn">from</span> <span class="nn">etl</span> <span class="kn">import</span> <span class="n">get_data</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">(</span><span class="n">targets</span><span class="p">):</span>
    <span class="k">if</span> <span class="s">'data'</span> <span class="ow">in</span> <span class="n">targets</span><span class="p">:</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'data-params.json'</span><span class="p">)</span> <span class="k">as</span> <span class="n">fh</span><span class="p">:</span>
            <span class="n">data_params</span> <span class="o">=</span> <span class="n">json</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">fh</span><span class="p">)</span>
        <span class="n">get_data</span><span class="p">(</span><span class="o">**</span><span class="n">data_params</span><span class="p">)</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">'__main__'</span><span class="p">:</span>
    <span class="n">targets</span> <span class="o">=</span> <span class="n">sys</span><span class="p">.</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
    <span class="n">main</span><span class="p">(</span><span class="n">targets</span><span class="p">)</span>
</code></pre></div></div><p>Note:</p><ul><li>The line at the top, <code class="language-plaintext highlighter-rouge">#!/usr/bin/env python</code>, is known as the “shebang.” It tells bash which Python installation to use (here, we specified our user’s default Python).<li>The <code class="language-plaintext highlighter-rouge">get_data</code> function from <code class="language-plaintext highlighter-rouge">etl</code> is imported.<li><code class="language-plaintext highlighter-rouge">__name__ == '__main__'</code> only evaluates to <code class="language-plaintext highlighter-rouge">True</code> when <code class="language-plaintext highlighter-rouge">run.py</code> is run as a script from the command-line.<ul><li><code class="language-plaintext highlighter-rouge">sys.argv</code> is a list of the arguments provided on the command-line when <code class="language-plaintext highlighter-rouge">run.py</code> is called. For instance, if we call <code class="language-plaintext highlighter-rouge">python run.py data dog zebra</code>, <code class="language-plaintext highlighter-rouge">sys.argv</code> is <code class="language-plaintext highlighter-rouge">['run.py', 'data', 'dog', 'zebra']</code>, and hence <code class="language-plaintext highlighter-rouge">sys.argv[1:]</code> is <code class="language-plaintext highlighter-rouge">['data', 'dog', 'zebra']</code>.<li>Our <code class="language-plaintext highlighter-rouge">main</code> function runs <code class="language-plaintext highlighter-rouge">get_data</code> from <code class="language-plaintext highlighter-rouge">etl</code> using the parameters in <code class="language-plaintext highlighter-rouge">data-params.json</code> only if <code class="language-plaintext highlighter-rouge">data</code> is one of the command-line arguments called with <code class="language-plaintext highlighter-rouge">python run.py</code>.</ul></ul><hr /><h2 id="a-final-template"> <a href="#a-final-template" class="anchor-heading" aria-labelledby="a-final-template"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> A Final Template</h2><h3 id="overview-1"> <a href="#overview-1" class="anchor-heading" aria-labelledby="overview-1"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Overview</h3><p>Hopefully the example above got you to think about <em>what</em> should be stored <em>where</em>. However, it is far too simplistic to be realistic – even modest projects will outgrow the previously provided template. In practice, your repositories will consist of several directories.</p><center><img src="assets/notebook.png" width="40%" /> </center><p>We’ve all written notebooks with uninsightful names, like <code class="language-plaintext highlighter-rouge">Untitled4-Copy1.ipynb</code>, that are impossible to run linearly because we wrote the code out-of-order. When working in such a notebook, especially one that you didn’t write yourself, it can be frustrating to try and figure out what order to run the code in the notebook in. To avoid this problem altogether, you should strive to regularly move your code from notebooks to source code files when appropriate.</p><h3 id="the-template"> <a href="#the-template" class="anchor-heading" aria-labelledby="the-template"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> The Template</h3><blockquote><p><em>We’re not talking about bikeshedding the indentation aesthetics or pedantic formatting standards – ultimately, data science code quality is about correctness and reproducibility. (<a href="https://drivendata.github.io/cookiecutter-data-science/">source</a>)</em></p></blockquote><p>By sticking to a strict template, you’re more likely to follow software development best practices and, as a result, produce methods and analyses that are more likely to be “correct.” In this class, we will largely follow a repository template outlined by the folks at <a href="https://drivendata.github.io/cookiecutter-data-science">Cookie Cutter Data Science</a>, who describe their template as “A logical, reasonably standardized, but flexible project structure for doing and sharing data science work.</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Project
├── .gitignore         &lt;- Files to keep out of version control (e.g. data/binaries).
├── run.py             &lt;- run.py with calls to functions in src.
├── README.md          &lt;- The top-level README for developers using this project.
├── data
│   ├── temp           &lt;- Intermediate data that has been transformed.
│   ├── out            &lt;- The final, canonical data sets for modeling.
│   └── raw            &lt;- The original, immutable data dump.
├── notebooks          &lt;- Jupyter notebooks (presentation only).
├── references         &lt;- Data dictionaries, explanatory materials.
├── requirements.txt   &lt;- For reproducing the analysis environment, e.g.
│                         generated with `pip freeze &gt; requirements.txt`
├── src                &lt;- Source code for use in this project.
    ├── data           &lt;- Scripts to download or generate data.
    │   └── make_dataset.py
    ├── features       &lt;- Scripts to turn raw data into features for modeling.
    │   └── build_features.py
    ├── models         &lt;- Scripts to train models and make predictions.
    │   ├── predict_model.py
    │   └── train_model.py
    └── visualization  &lt;- Scripts to create exploratory and results-oriented viz.
        └── visualize.py
</code></pre></div></div><p>Let’s take a closer look at a few of the components of this template.</p><h4 id="data"> <a href="#data" class="anchor-heading" aria-labelledby="data"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <code class="language-plaintext highlighter-rouge">data</code></h4><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>├── data
│   ├── temp           &lt;- Intermediate data that has been transformed.
│   ├── out            &lt;- The final, canonical data sets for modeling.
│   └── raw            &lt;- The original, immutable data dump.
</code></pre></div></div><p>Note that all of your results are derived from raw data, i.e. the contents in <code class="language-plaintext highlighter-rouge">data/raw</code>. <strong>Never edit this raw data</strong>, so that you always have the option of “undoing” parts of your project. Ideally, store raw data such that it is read-only (this is an option on, say, DSMLP).</p><p>Since raw data never changes, it should not be included in version control. And since transformed data is generated by running source code on the raw data, transformed data should not be included in version control either. <strong>As a result, you should add <code class="language-plaintext highlighter-rouge">data/</code> to your <code class="language-plaintext highlighter-rouge">.gitignore</code></strong>.</p><p>Ultimately, you should be able to re-create the final outputs of your pipeline given just the raw data.</p><h4 id="notebooks"> <a href="#notebooks" class="anchor-heading" aria-labelledby="notebooks"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <code class="language-plaintext highlighter-rouge">notebooks</code></h4><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>├── notebooks          &lt;- Jupyter notebooks (presentation only).
</code></pre></div></div><p>Notebooks are meant for analysis and communication, not for storing source code. The majority of your notebooks should be made up of Markdown and visualization; there should be very little code, and most of the code there should consist of calls to the functions in your source code. Whenever you’ve written code that should be included in version control, move it to your source code files.</p><p>It’s worth mentioning that the default notebook names (like <code class="language-plaintext highlighter-rouge">Untitled4-Copy1.ipynb</code>, for instance) are not very descriptive – instead, give your notebooks meaningful titles, like <code class="language-plaintext highlighter-rouge">03-rampure-prelim-EDA.ipynb</code>.</p><h4 id="requirementstxt"> <a href="#requirementstxt" class="anchor-heading" aria-labelledby="requirementstxt"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <code class="language-plaintext highlighter-rouge">requirements.txt</code></h4><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>├── requirements.txt   &lt;- For reproducing the analysis environment, e.g. generated with `pip freeze &gt; requirements.txt`
</code></pre></div></div><p>If I want to run your project from scratch, in addition to all of your code, I need to know which Python packages (and which versions) to install. The easiest way to communicate this information to others is through a <code class="language-plaintext highlighter-rouge">requirements.txt</code> file that contains all Python libraries that were used in your project. To create such a file, run <code class="language-plaintext highlighter-rouge">pip freeze &gt; requirements.txt</code> in your project repository.</p><p>In the coming weeks, we’ll learn how to containerize an entire environment (i.e. more than just Python packages) to distrbute to others.</p><h3 id="examples"> <a href="#examples" class="anchor-heading" aria-labelledby="examples"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Examples</h3><p>Several realistic examples that follow this general structure can be found in <a href="https://github.com/DSC-Capstone/project-templates">this repository</a>. Note that they don’t all follow the template exactly; you’re free to make changes to best suit your projects, but should generally follow the spirit of the template. <strong>Your code throughout the capstone program (including in Methodology Assignment 2) will be graded on how closely it adheres to this structure!</strong></p></div></div><div class="search-overlay"></div></div>
